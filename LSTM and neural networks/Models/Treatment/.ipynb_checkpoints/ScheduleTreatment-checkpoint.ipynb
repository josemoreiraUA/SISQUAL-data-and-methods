{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "special-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import ast\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "optional-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days: 1649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24, 22, 35, ..., 22, 25, 28], dtype=int64)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the csv file\n",
    "\n",
    "dataset = pd.read_csv('new_stores/store_0057.csv', header=0, infer_datetime_format=True,\n",
    "                   parse_dates=['ds'], index_col=['ds'])\n",
    "\n",
    "n_days = len(dataset.groupby(dataset.index.date))\n",
    "print(\"days: \"+str(n_days))\n",
    "dataset = dataset[['sales','n_clients']]\n",
    "dataset.n_clients.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-comparative",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "linear-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#naive_yhat_sequence=dataset['clients_that_bought'].values[-1400-175+(175*i):-1400+(175*i)]\n",
    "# plot each iteration \n",
    "pyplot.title('Store A')\n",
    "    pyplot.plot(test_y, color=\"blue\", label=\"Real\")\n",
    "    pyplot.plot(yhat_sequence, alpha=0.8, color=\"red\", label=\"LSTM Prediction\")\n",
    "    #pyplot.plot(naive_yhat_sequence, alpha=0.8, color=\"green\", label=\"Naive Predicted\")\n",
    "    #pyplot.xticks([0, 25, 50, 75, 100, 125, 150, 175], labels=['2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08'])\n",
    "    #pyplot.xticks([0, 25, 50, 75, 100, 125, 150, 175], labels=['2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14', '2020-04-15'])\n",
    "    #pyplot.xticks([0, 25, 50, 75, 100, 125, 150, 175], labels=['2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22'])\n",
    "    #pyplot.xticks([0, 175, 350, 525, 700], labels=['2020-04-29', '2020-05-06', '2020-05-13', '2020-05-20', '2020-05-27'])\n",
    "    pyplot.legend(loc=\"upper left\")\n",
    "    pyplot.xlabel(\"Half-hours\")\n",
    "    pyplot.ylabel(\"Client Entries\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "whole-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_regular_schedule(df):\n",
    "    check_dict = dict()\n",
    "    # iterate by days\n",
    "    for idx, day in df.groupby(df.index.date):\n",
    "        day_sched = list()\n",
    "        # get list(keys-schedules) for the dict\n",
    "        for i in day.index.time:\n",
    "            hour = i.strftime(\"%H:%M:%S\")\n",
    "            day_sched.append(hour)\n",
    "        day_sched = str(day_sched)\n",
    "        if day_sched in check_dict:\n",
    "            check_dict[day_sched]+=1\n",
    "        else:\n",
    "            check_dict.update({day_sched : 1})\n",
    "    \n",
    "    # the schedule with max ocurrences\n",
    "    k, v = max(check_dict.items(), key=operator.itemgetter(1))\n",
    "    k = ast.literal_eval(k)\n",
    "    \n",
    "    return k,v, check_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "loaded-fellowship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00'] 282\n"
     ]
    }
   ],
   "source": [
    "reg_schedule, v, check_dict = get_most_regular_schedule(dataset)\n",
    "print(reg_schedule,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "funded-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gaps(df, reg_schedule=None, hour_in=None, hour_out=None):\n",
    "    counter = 0 # counter of imputations to perform\n",
    "    \n",
    "    # create custom schedule with hour_in and hour_out\n",
    "    if hour_in is not None and hour_out is not None:\n",
    "        hour_in = datetime.strptime(hour_in, '%H:%M:%S')\n",
    "        hour_out = datetime.strptime(hour_out, '%H:%M:%S')\n",
    "        reg_schedule = list()\n",
    "        while hour_in <= hour_out:\n",
    "            reg_schedule.append(str(datetime.strptime(str(hour_in.time()), '%H:%M:%S').time()))\n",
    "            hour_in+=timedelta(minutes=30)\n",
    "        print(reg_schedule)\n",
    "        \n",
    "    # fill the gaps with NaN\n",
    "    for i in reg_schedule:\n",
    "        i = datetime.strptime(i, '%H:%M:%S').time()\n",
    "        print(i)\n",
    "        for j, day in df.groupby(df.index.date):\n",
    "            if i not in list(day.index.time):\n",
    "                #print(i, day)\n",
    "                df.loc[pd.to_datetime(str(j)+\" \"+str(i))] = [np.nan,np.nan]\n",
    "                counter+=1\n",
    "                \n",
    "    # add column \"imputed\"\n",
    "    df['imputed'] = np.where(((pd.isnull(df['n_clients'])) & (pd.isnull(df['sales']))), 'yes', 'no')\n",
    "    \n",
    "    print(\"Total rows to input: \"+str(counter))\n",
    "    df = df.sort_index()     \n",
    "    \n",
    "    # Dataframe with NaNs to be imputed and excess datetimes\n",
    "    return df       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "geological-yukon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:00:00\n",
      "08:30:00\n",
      "09:00:00\n",
      "09:30:00\n",
      "10:00:00\n",
      "10:30:00\n",
      "11:00:00\n",
      "11:30:00\n",
      "12:00:00\n",
      "12:30:00\n",
      "13:00:00\n",
      "13:30:00\n",
      "14:00:00\n",
      "14:30:00\n",
      "15:00:00\n",
      "15:30:00\n",
      "16:00:00\n",
      "16:30:00\n",
      "17:00:00\n",
      "17:30:00\n",
      "18:00:00\n",
      "18:30:00\n",
      "19:00:00\n",
      "Total rows to input: 9059\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>n_clients</th>\n",
       "      <th>imputed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02 08:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 08:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 10:00:00</th>\n",
       "      <td>121.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 17:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 17:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 18:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 18:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 19:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40176 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sales  n_clients imputed\n",
       "ds                                           \n",
       "2015-01-02 08:00:00    NaN        NaN     yes\n",
       "2015-01-02 08:30:00    NaN        NaN     yes\n",
       "2015-01-02 09:00:00    NaN        NaN     yes\n",
       "2015-01-02 09:30:00    NaN        NaN     yes\n",
       "2015-01-02 10:00:00  121.0        2.0      no\n",
       "...                    ...        ...     ...\n",
       "2020-10-18 17:00:00    NaN        NaN     yes\n",
       "2020-10-18 17:30:00    NaN        NaN     yes\n",
       "2020-10-18 18:00:00    NaN        NaN     yes\n",
       "2020-10-18 18:30:00    NaN        NaN     yes\n",
       "2020-10-18 19:00:00    NaN        NaN     yes\n",
       "\n",
       "[40176 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = fill_gaps(dataset, reg_schedule)#, hour_in='08:00:00', hour_out='12:00:00')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "respiratory-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00'] : 1673 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '20:00:00', '21:00:00'] : 1 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '23:00:00'] : 1 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '20:00:00', '21:00:00', '22:00:00', '23:00:00'] : 1 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '20:00:00'] : 3 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '21:00:00'] : 2 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '20:00:00', '21:00:00', '23:00:00'] : 3 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '20:00:00', '22:00:00'] : 1 \n",
      "\n",
      "['07:30:00', '08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '22:00:00', '23:00:00'] : 1 \n",
      "\n",
      "['07:30:00', '08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00'] : 36 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '20:00:00', '21:00:00', '22:00:00'] : 1 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '19:30:00'] : 17 \n",
      "\n",
      "['07:00:00', '08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00'] : 1 \n",
      "\n",
      "['08:00:00', '08:30:00', '09:00:00', '09:30:00', '10:00:00', '10:30:00', '11:00:00', '11:30:00', '12:00:00', '12:30:00', '13:00:00', '13:30:00', '14:00:00', '14:30:00', '15:00:00', '15:30:00', '16:00:00', '16:30:00', '17:00:00', '17:30:00', '18:00:00', '18:30:00', '19:00:00', '19:30:00', '20:00:00'] : 2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check schedules again\n",
    "reg_schedule, v, check_dict = get_most_regular_schedule(dataset)\n",
    "\n",
    "# see other schedules as well\n",
    "for x, y in check_dict.items():\n",
    "    print(str(x)+\" : \"+str(y)+\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fatty-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to test a break in the schedule\n",
    "# del reg_schedule[9:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "accredited-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-regular time rows\n",
    "def filter_schedule(df, schedule):\n",
    "    # convert schedule to datetime pd.Series\n",
    "    pd_schedule = pd.to_datetime(pd.Series(schedule))\n",
    "    # create a sequence of indexed halfhours\n",
    "    pd_schedule = pd_schedule.dt.strftime('%H').astype('int64')*2 + pd_schedule.dt.strftime('%M').astype('int64')//30\n",
    "    \n",
    "    # check if the schedule is continuous\n",
    "    if (max(pd_schedule) - min(pd_schedule) + 1 == len(pd_schedule)):\n",
    "        # no breaks\n",
    "        df = df.between_time(schedule[0], schedule[-1])\n",
    "    else:\n",
    "        # there is a break\n",
    "        df_schedule = pd.DataFrame({'time':schedule, 'hh':pd_schedule})\n",
    "        # find break\n",
    "        for i in df_schedule.index:\n",
    "            if (df_schedule.at[i+1,'hh'] - df_schedule.at[i,'hh']) != 1:\n",
    "                break\n",
    "        close_morning = df_schedule.at[i,'time']\n",
    "        open_afternoon = df_schedule.at[i+1,'time']\n",
    "        #print('break from',close_morning,'to',open_afternoon)\n",
    "        # make 2 splits\n",
    "        df1 = df.between_time(schedule[0], close_morning)\n",
    "        df2 = df.between_time(open_afternoon, schedule[-1])\n",
    "        # join\n",
    "        df = pd.concat([df1, df2]).sort_index()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "electric-money",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>n_clients</th>\n",
       "      <th>imputed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02 08:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 08:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 09:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-02 10:00:00</th>\n",
       "      <td>121.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 17:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 17:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 18:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 18:30:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-18 19:00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40089 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sales  n_clients imputed\n",
       "ds                                           \n",
       "2015-01-02 08:00:00    NaN        NaN     yes\n",
       "2015-01-02 08:30:00    NaN        NaN     yes\n",
       "2015-01-02 09:00:00    NaN        NaN     yes\n",
       "2015-01-02 09:30:00    NaN        NaN     yes\n",
       "2015-01-02 10:00:00  121.0        2.0      no\n",
       "...                    ...        ...     ...\n",
       "2020-10-18 17:00:00    NaN        NaN     yes\n",
       "2020-10-18 17:30:00    NaN        NaN     yes\n",
       "2020-10-18 18:00:00    NaN        NaN     yes\n",
       "2020-10-18 18:30:00    NaN        NaN     yes\n",
       "2020-10-18 19:00:00    NaN        NaN     yes\n",
       "\n",
       "[40089 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = filter_schedule(dataset, reg_schedule)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sitting-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imput missing data day-by-day\n",
    "def input_inday(df, method='linear'):\n",
    "    # ignore pandas.loc warning\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    # get list of days\n",
    "    for dt in np.unique(df.index.date):\n",
    "        # input each day individualy\n",
    "        df.loc[str(dt)] = df.loc[str(dt)].interpolate(method=method, limit_direction='both')\n",
    "        \n",
    "    warnings.filterwarnings('default')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brave-point",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 40089 entries, 2015-01-02 08:00:00 to 2020-10-18 19:00:00\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   sales      40089 non-null  float64\n",
      " 1   n_clients  40089 non-null  float64\n",
      " 2   imputed    40089 non-null  object \n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset = input_inday(dataset, method='linear')\n",
    "dataset.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
