{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log, exp, sqrt, sin, cos, pi\n",
    "import numpy\n",
    "from numpy import split, array, arctan, mean, zeros, sin, cos, pi, arange, concatenate\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, LSTM\n",
    "from tensorflow.python.keras.layers import RepeatVector, TimeDistributed, Bidirectional, Dropout\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.style.use('ggplot')\n",
    "\n",
    "from IPython.display import Image \n",
    "import datetime, os\n",
    "\n",
    "pyplot.rcParams['figure.dpi'] = 100\n",
    "pyplot.rcParams['figure.figsize'] = [12,5]\n",
    "matplotlib.rc('lines', linewidth=1, linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAAPE metric -> does not have the same behaviour as MAPE for actual values close to zero, which is good\n",
    "\n",
    "def mean_arctangent_absolute_percentage_error(actual, predicted):\n",
    "    return mean(arctan(abs((actual - predicted) / actual))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def build_model(train, n_input, n_output, stride, units=32, epochs=50, batch_size=0):\n",
    "    # prepare data\n",
    "    train_x, train_y = to_supervised(train, n_input, n_output, stride)\n",
    "    # Model variables\n",
    "    verbose = 1 #batch_size 1 IS SGD, 1<BATCH_SIZE<SIZE IS MINIBATCH GD AND BATCH_SIZE=SIZE IS BATCH GD\n",
    "    n_timesteps, n_features = train_x.shape[1], train_x.shape[2]\n",
    "    \n",
    "    # final data preparation for the model\n",
    "    # reshape train_output into [samples, timesteps, features] for the LSTMs\n",
    "    train_y = train_y.reshape(train_y.shape[0], train_y.shape[1], 1)\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # VANILLA LSTM\n",
    "    \n",
    "    model.add(LSTM(units, activation='tanh', input_shape=(n_timesteps, n_features)))\n",
    "    model.add((Dense(n_output)))\n",
    "    \n",
    "    model.compile(loss=\"mse\", optimizer='adam', metrics=[\"mae\"])  #Reminder: LOSS function is MSE but others can be used!\n",
    "    \n",
    "    early = tensorflow.keras.callbacks.EarlyStopping('loss', patience=5)\n",
    "\n",
    "    # fit network\n",
    "    history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=verbose, callbacks=[early]) #tensorboard_callback,\n",
    "    print(model.summary())\n",
    "    pyplot.plot(history.history['loss'])\n",
    "    pyplot.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     sales  n_clients imputed\n",
      "ds                                           \n",
      "2015-01-02 09:00:00  49.12       24.0     yes\n",
      "2015-01-02 09:30:00  49.12       24.0     yes\n",
      "2015-01-02 10:00:00  49.12       24.0      no\n",
      "2015-01-02 10:30:00  42.00       22.0      no\n",
      "2015-01-02 11:00:00  88.10       35.0      no\n",
      "...                    ...        ...     ...\n",
      "2019-07-23 19:00:00  63.23       21.0      no\n",
      "2019-07-23 19:30:00  41.00       18.0      no\n",
      "2019-07-23 20:00:00  39.00       22.0      no\n",
      "2019-07-23 20:30:00  70.00       25.0      no\n",
      "2019-07-23 21:00:00  59.00       28.0      no\n",
      "\n",
      "[41225 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the csv file\n",
    "# ../old_data//30min/30minstore290.csv\n",
    "# ../old_data/30min/30minstore1027.csv\n",
    "# ../30min/30minstore274.csv\n",
    "# special case01: ../old_data/30min/partial_covid_stationary_sliced_30minstore274.csv\n",
    "# special case02: ../old_data/30min/full_covid_nonstationary_sliced_30minstore274.csv\n",
    "# predict covid:  ../old_data/30min/predict_covid_30minstore274\n",
    "\n",
    "\n",
    "# NEW STORES\n",
    "# ../Treatment/imputed_stores/linear_interp_store0057.csv\n",
    "# ../Treatment/new_stores/store_0057.csv\n",
    "\n",
    "# ../Treatment/imputed_stores/linear_interp_store4969.csv\n",
    "# ../Treatment/new_stores/store_4969.csv\n",
    "\n",
    "# IMPUTED DATASET\n",
    "dataset = pd.read_csv('../Treatment/imputed_stores/linear_interp_store0057.csv', header=0, infer_datetime_format=True,parse_dates=['ds'], index_col=['ds'])\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     n_clients\n",
      "ds                            \n",
      "2015-01-02 09:00:00         24\n",
      "2015-01-02 09:30:00         24\n",
      "2015-01-02 10:00:00         24\n",
      "2015-01-02 10:30:00         22\n",
      "2015-01-02 11:00:00         35\n",
      "...                        ...\n",
      "2019-07-23 19:00:00         21\n",
      "2019-07-23 19:30:00         18\n",
      "2019-07-23 20:00:00         22\n",
      "2019-07-23 20:30:00         25\n",
      "2019-07-23 21:00:00         28\n",
      "\n",
      "[41225 rows x 1 columns] 1\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS\n",
    "n_input = 25                 # steps used to predict (autoregressive order) p\n",
    "n_output = 750              # steps to predict (forecast horizon) H\n",
    "data_split = n_output        # to split the data in windows\n",
    "stride = 1                   # stride value for the sliding window method (overlapped vs non-overlapped)\n",
    "init_train_set = 725           # refers to when the train_set starts, this is useful for the sliding window method\n",
    "imputed = True                # To remove idxs in evaluation from a supposed imputed model\n",
    "\n",
    "# Add n_output (H) zeros to the dataset to get the real FUTURE predictions\n",
    "future_prediction = True\n",
    "\n",
    "if imputed:\n",
    "    # if imputed is true this will be used; its to remove hours that cannot be compared with an imputed model\n",
    "    imputed_idx = numpy.where(dataset.imputed==\"yes\")[0].tolist()\n",
    "\n",
    "# Univariate\n",
    "dataset = dataset.iloc[init_train_set:]\n",
    "dataset = dataset[['n_clients']]\n",
    "dataset = dataset.astype('int64')\n",
    "n_features = len(dataset.columns)\n",
    "print(dataset, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41225, 1)\n"
     ]
    }
   ],
   "source": [
    "values = dataset.values\n",
    "\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "print(values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41225\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array split does not result in an equal division",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\miniconda3\\envs\\backup\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[0;32m    866\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 867\u001b[1;33m         \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_or_sections\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    868\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'float' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6a107299f01d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# restructure into windows, for the sliding window method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdata_split\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msplit\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\backup\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mN\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msections\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m             raise ValueError(\n\u001b[1;32m--> 873\u001b[1;33m                 'array split does not result in an equal division')\n\u001b[0m\u001b[0;32m    874\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marray_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_or_sections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: array split does not result in an equal division"
     ]
    }
   ],
   "source": [
    "# split into train and test, leave the last test_set blocks for n_output timesteps\n",
    "train = values\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler() #MinMaxScaler(feature_range=(0, 1)) \n",
    "train = scaler.fit_transform(train)\n",
    "\n",
    "#for walkforward\n",
    "def normalize_train(scaler, train):\n",
    "    train = scaler.fit_transform(train)\n",
    "    return train\n",
    "print(len(train))\n",
    "# restructure into windows, for the sliding window method\n",
    "train = array(split(train, len(train) / data_split))\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert history into inputs and outputs - framing to a supervised learning problem\n",
    "def to_supervised(train, n_input, n_output, stride=1):\n",
    "    # flatten data\n",
    "    data = train.reshape(train.shape[0] * train.shape[1], train.shape[2])\n",
    "    train_x, train_y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one STRIDE step at a time\n",
    "    for _ in range(0, len(data), stride):\n",
    "        # define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_output\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            #print(\"iteration\")\n",
    "            #print(_)\n",
    "            #print(\"x\")\n",
    "            #print(in_start,in_end)\n",
    "            #print(\"y\")\n",
    "            #print(in_end,out_end)\n",
    "            train_x.append(data[in_start:in_end, :])\n",
    "            train_y.append(data[in_end:out_end, 0])\n",
    "        # move along stride time steps\n",
    "        in_start += stride\n",
    "    print(array(train_x).shape, array(train_y).shape)\n",
    "    return array(train_x), array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the multi-step forecast\n",
    "def forecast(model, history, n_input):\n",
    "    # flatten data\n",
    "    data = array(history)\n",
    "    data = data.reshape((data.shape[0] * data.shape[1], data.shape[2]))\n",
    "    \n",
    "    # retrieve last n_input observations to predict with\n",
    "    input_x = data[-n_input:, :]\n",
    "    \n",
    "    # reshape into [1, n_input, n]\n",
    "    input_x = input_x.reshape((1, input_x.shape[0], input_x.shape[1]))\n",
    "    \n",
    "    # forecast the next n_output steps\n",
    "    yhat = model.predict(input_x, verbose=0)\n",
    "    \n",
    "    # we only want the forecast variable\n",
    "    yhat = yhat[0]\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert the scaling\n",
    "def invTransformTarget(scaler, data):\n",
    "    dummy = pd.DataFrame(zeros((len(data), scaler.n_features_in_)))\n",
    "    dummy[0] = data\n",
    "    dummy = pd.DataFrame(scaler.inverse_transform(dummy), columns=dummy.columns)\n",
    "    return dummy[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%matplotlib notebook\n",
    "# history of windows, is updated for each prediction\n",
    "history = [x for x in train]\n",
    "\n",
    "# the model is trained and retrained for every number of n_output to predict\n",
    "model = build_model(array(history), n_input, n_output, stride)  \n",
    "train_size = len(history) # number of training windows\n",
    "len_train = train_size*n_output # actual training size/length\n",
    "            \n",
    "\n",
    "# predict the next n_output steps\n",
    "yhat_sequence = forecast(model, history, n_input)\n",
    "    \n",
    "print(\"Test unnormalized error to compare to training loss:\") \n",
    "print(mean_squared_error(array(test[i, :, 0]).flatten(), yhat_sequence))\n",
    "    \n",
    "# invert the scaling on predictions\n",
    "yhat_sequence = invTransformTarget(scaler, yhat_sequence)\n",
    "        \n",
    "if imputed:\n",
    "    print(len_train)\n",
    "    list_idx = []\n",
    "    for idx in imputed_idx:\n",
    "        if len_train-1<idx<len_train+n_output:\n",
    "            list_idx.append(idx - len_train)\n",
    "    if list_idx:\n",
    "        yhat_sequence = numpy.delete(yhat_sequence,  list_idx)\n",
    "        test_y = numpy.delete(test_y,  list_idx)  \n",
    "        print(\"The following errors are calculated without the imputed observations!\\n\")\n",
    "    \n",
    "    # plot results\n",
    "    pyplot.title('Last 30 days')\n",
    "    #pyplot.plot(test_y, color=\"blue\", label=\"Real\")\n",
    "    pyplot.plot(yhat_sequence, alpha=0.8, color=\"red\", label=\"LSTM Prediction\")\n",
    "    pyplot.legend(loc=\"upper left\")\n",
    "    pyplot.xlabel(\"Half-hours\")\n",
    "    pyplot.ylabel(\"Client Entries\")\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "backup",
   "language": "python",
   "name": "backup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
